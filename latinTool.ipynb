{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3098a0ac",
   "metadata": {},
   "source": [
    "## Latin pedagogy tool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1aee7",
   "metadata": {},
   "source": [
    "We make use of the CLTK library, a NLP library for classical languages.\n",
    "\n",
    "**Introduction** : https://aclanthology.org/2021.acl-demo.3.pdf\n",
    "\n",
    "**Documentation**\n",
    "* API : https://docs.cltk.org/en/latest/index.html\n",
    "* Demos : https://github.com/cltk/cltk/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fa6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Architecti est scientia pluribus disciplinis et variis eruditionibus ornata, quae ab ceteris artibus perficiuntur.\n",
    "Opera ea nascitur et fabrica et ratiocinatione.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4b5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = get_corpus_reader(corpus_name='latin_text_perseus', language='latin')\n",
    "from cltk.data.fetch import FetchCorpus\n",
    "corpus_downloader = FetchCorpus(language=\"lat\")\n",
    "corpus_downloader.import_corpus('lat_text_perseus')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1239f92",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "Text preprocessing is an important step for NLP tasks. The processing performed should be tailored around the idiosyncrasies of the text and objective of the task.\n",
    "\n",
    "#### Processing of non-informative attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54675bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.alphabet.lat import normalize_lat\n",
    "from cltk.alphabet.lat import swallow_angle_brackets\n",
    "from cltk.alphabet.lat import swallow_square_brackets\n",
    "from cltk.alphabet.lat import swallow_braces\n",
    "import re\n",
    "\n",
    "# Removes any non-digit, non-letter character\n",
    "def removePunc(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Removes meta-info (e.g. [5], [c 1Kb], {PRO.})\n",
    "def removeMeta(text):\n",
    "\n",
    "    text = swallow_angle_brackets(text)\n",
    "    text = swallow_square_brackets(text)\n",
    "    text = swallow_braces(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Normalise a text based on Latin unique features\n",
    "def normalizeLatText(text):\n",
    "\n",
    "    text = normalize_lat(\n",
    "        text,\n",
    "        drop_accents=True,          # √° -> a\n",
    "        drop_macrons=True,          # ƒÅ -> a\n",
    "        jv_replacement=True,        # verus -> uerus\n",
    "        ligature_replacement=True)  # √¶ -> ae, ≈ì -> oe\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Define final function to process text how we want to\n",
    "# This should be changed according to the document\n",
    "def cleanDoc(text, convertLower=False):\n",
    "    # text = normalizeLatText(text)\n",
    "    text = removePunc(removeMeta(text))\n",
    "    text = text.replace(\"   \", \" \").replace(\"  \", \" \")\n",
    "    return text.lower() if convertLower else text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1df8a808",
   "metadata": {},
   "source": [
    "The order of removing punctuation and meta-information is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7316f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing punctuation first : '33 Quid est enim'\n",
      "Removing meta-information first : 'Quid est enim '\n"
     ]
    }
   ],
   "source": [
    "t = \"[33] Quid est enim ...\"\n",
    "print(f\"Removing punctuation first : '{removeMeta(removePunc(t))}'\")\n",
    "print(f\"Removing meta-information first : '{removePunc(removeMeta(t))}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "287ed74c",
   "metadata": {},
   "source": [
    "#### Macronizer\n",
    "\n",
    "Vowel lengths (indicated by macrons) are quite important in Latin, especially with regards to poetry scansion. However many publishers persist to omit them either out of ignorance or tradition. The following is one method to macronize a given text, though its performance is not ideal. A better alternative (from experience) is provided here https://github.com/Alatius/latin-macronizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da228339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example : Architecti est scientia pluribus -> architectƒ´ est scientiƒÅ pl≈´ribus\n"
     ]
    }
   ],
   "source": [
    "from cltk.prosody.lat.macronizer import Macronizer\n",
    "\n",
    "def macronizer(text: str) -> str:\n",
    "    macronizer = Macronizer(\"tag_tnt\")\n",
    "    text = macronizer.macronize_text(text)\n",
    "    return text\n",
    "\n",
    "tƒìxt = macronizer(text)\n",
    "print(f\"Example : {text[:32]} -> {tƒìxt[:32]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6e3790c",
   "metadata": {},
   "source": [
    "#### Lemmatizer\n",
    "\n",
    "Lemmatisation is a process that reduces the inflected form of a word back to its lemma (dictionary form). This is incredibly important for Latin, a highly inflected language, much so than any other modern Indo-European language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ce17659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example : ['filias', 'pueri', 'cecini', 'variis'] -> ['filia', 'puer', 'cano', 'varius1']\n"
     ]
    }
   ],
   "source": [
    "from cltk.lemmatize.lat import LatinBackoffLemmatizer\n",
    "from cltk.alphabet.lat import drop_latin_punctuation\n",
    "\n",
    "# Returns tuples of (original, root)\n",
    "# Requires lower-case, non-macron inputs\n",
    "def lemmatize(tokens: list)-> list:\n",
    "    lemmatizer = LatinBackoffLemmatizer()\n",
    "    tokens = lemmatizer.lemmatize(tokens)\n",
    "    return [root for _, root in tokens]\n",
    "\n",
    "tokens = [\"filias\", \"pueri\", \"cecini\", \"variis\"]\n",
    "print(f\"Example : {tokens} -> {lemmatize(tokens)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c65254f0",
   "metadata": {},
   "source": [
    "#### Decliner\n",
    "\n",
    "This is the opposite of lemmatisation, generating all the possible inflections of a given lemma. The cltk decliner returns a dictionary containing tuples of the inflected form and its respective declension encoding (https://github.com/cltk/latin_treebank_perseus#readme). <br> \n",
    "\n",
    "E.g. --s----n- => singular nominative\n",
    "\n",
    "It can be used to construct declension tables as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73a60c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case        Singular    Plural\n",
      "----------  ----------  --------\n",
      "Nominative  le≈ç         le≈çnƒìs\n",
      "Genitive    le≈çnis      le≈çnum\n",
      "Dative      le≈çnƒ´       le≈çnibus\n",
      "Accusative  le≈çnem      le≈çnƒìs\n",
      "Ablative    le≈çne       le≈çnibus\n"
     ]
    }
   ],
   "source": [
    "from cltk.morphology.lat import CollatinusDecliner\n",
    "from collections import OrderedDict\n",
    "from tabulate import tabulate\n",
    "\n",
    "words = ['leo', 'via']\n",
    "def declensions(rootWords: list)-> dict:\n",
    "    dec, decliner = {}, CollatinusDecliner()\n",
    "    for word in rootWords:\n",
    "        # Expect root words only\n",
    "        try:\n",
    "            dec[word] = decliner.decline(word)\n",
    "        except Exception:\n",
    "            print('Not a root word')\n",
    "    return dec\n",
    "\n",
    "# Usage example : declension table (only nouns for now)\n",
    "def printDecTable(lemma):\n",
    "\n",
    "    rows = []\n",
    "    cases = {'n':'Nominative',\n",
    "             'g':'Genitive',\n",
    "             'd':'Dative',\n",
    "             'a':'Accusative',\n",
    "             'b':'Ablative'}\n",
    "\n",
    "    d = OrderedDict({c: {} for c in cases.keys()})\n",
    "    declens = CollatinusDecliner().decline(lemma)\n",
    "\n",
    "    for dec, code in declens:\n",
    "        number, case = code[2], code[7]\n",
    "        if case in d: d[case][number] = macronizer(dec).lower()\n",
    "\n",
    "    for key, val in d.items():\n",
    "        row =[cases[key]]+list(val.values())\n",
    "        rows.append(row)\n",
    "\n",
    "    print(tabulate(rows, headers=['Case', 'Singular', 'Plural']))\n",
    "\n",
    "decs = declensions(words)\n",
    "printDecTable(\"leo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59a21599",
   "metadata": {},
   "source": [
    "#### Tokenizer\n",
    "\n",
    "Tokenisation is the task of chopping a text up into pieces. The most common basis for tokenisation are sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41995ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['architecti est scientia pluribus disciplinis et variis eruditionibus ornata '\n",
      " 'quae ab ceteris artibus perficiuntur']\n",
      "['architecti', 'est', 'scientia', 'pluribus', 'disciplinis']\n"
     ]
    }
   ],
   "source": [
    "from cltk.sentence.lat import LatinPunktSentenceTokenizer\n",
    "from cltk.tokenizers.lat.lat import LatinWordTokenizer\n",
    "import pprint\n",
    "\n",
    "# Sentence tokenizer\n",
    "def sent_Tokenize(doc: str, punct=True) -> list:\n",
    "    sent_tokenize = LatinPunktSentenceTokenizer()\n",
    "    sentences = sent_tokenize.tokenize(doc)\n",
    "    return [removePunc(s).lower() for s in sentences] if punct else sentences\n",
    "\n",
    "# Word tokenizer\n",
    "def word_Tokenizer(sent: str) -> list:\n",
    "    word_tokenize = LatinWordTokenizer()\n",
    "    tokens = word_tokenize.tokenize(sent)\n",
    "    return tokens\n",
    "\n",
    "sentences = sent_Tokenize(text)\n",
    "tokens = word_Tokenizer(sentences[0])\n",
    "\n",
    "pprint.pprint(sentences[:1])\n",
    "pprint.pprint(tokens[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad100471",
   "metadata": {},
   "source": [
    "## 2. NLP pipeline\n",
    "\n",
    "The CLTK library also has a pre-configured NLP pipeline for latin. It automatically tokenises the text and processes information (such as gender, case etc.) into each `Word` token/object and creates embeddings that can be used for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc6a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.6'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "from cltk import NLP\n",
    "cltk_nlp = NLP(language=\"lat\")\n",
    "\n",
    "text = removePunc(cleanDoc(text, convertLower=True))\n",
    "cltk_doc = cltk_nlp.analyze(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "181e17ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_char_start': None,\n",
       " 'index_char_stop': None,\n",
       " 'index_token': 2,\n",
       " 'index_sentence': 0,\n",
       " 'string': 'scientia',\n",
       " 'pos': noun,\n",
       " 'lemma': 'scientia',\n",
       " 'stem': None,\n",
       " 'scansion': None,\n",
       " 'xpos': 'A1|grn1|casA|gen2|vgr1',\n",
       " 'upos': 'NOUN',\n",
       " 'dependency_relation': 'nsubj',\n",
       " 'governor': 0,\n",
       " 'features': {Case: [nominative], Gender: [feminine], Number: [singular]},\n",
       " 'category': {F: [neg], N: [pos], V: [neg]},\n",
       " 'embedding': array([-2.8462e-01,  6.4238e-01, -4.0037e-01,  3.9382e-01,  6.0418e-02,\n",
       "         2.7501e-01,  3.1526e-01,  2.9083e-01, -1.4485e-02,  1.7901e-01,\n",
       "         2.2285e-01,  6.7856e-01, -1.6518e-01, -9.1198e-02,  2.8839e-01,\n",
       "         3.6772e-01, -1.6601e-01, -4.8859e-01,  4.9720e-02,  2.7487e-01,\n",
       "         9.4751e-02, -1.2327e-01,  1.5279e-01, -1.9930e-01,  5.3575e-01,\n",
       "        -3.5485e-02,  5.1619e-01,  1.4068e-01,  3.3552e-01, -2.2774e-01,\n",
       "        -8.7011e-01, -5.3603e-01,  5.3102e-01, -3.0086e-01, -1.0687e-01,\n",
       "        -7.3727e-01, -1.0646e-01, -7.2034e-01, -1.4764e-01, -1.2940e-01,\n",
       "         2.3322e-02, -3.7496e-01,  6.9163e-01, -5.1657e-02, -1.2794e-02,\n",
       "         3.6363e-01, -2.1873e-01, -1.6160e-01, -2.9296e-01, -1.0043e-01,\n",
       "        -3.3556e-01,  6.2063e-02, -1.4634e-01,  6.1967e-02, -5.6635e-01,\n",
       "         3.9456e-01, -3.0131e-01, -5.6847e-02,  1.2561e-01,  2.7367e-01,\n",
       "         1.8238e-01,  2.1233e-01,  2.9857e-01,  1.5239e-01,  1.4429e-01,\n",
       "         7.9523e-02, -7.0363e-02, -5.1192e-01, -1.3209e-01, -8.0047e-02,\n",
       "        -3.6631e-01,  6.7257e-01, -2.9829e-01,  4.0113e-02, -8.1207e-02,\n",
       "        -6.8888e-03,  4.6267e-01,  1.7940e-01, -9.7433e-02, -9.2745e-01,\n",
       "        -4.3534e-01, -1.0922e-01,  2.4155e-01,  7.7877e-02, -3.3957e-01,\n",
       "        -4.7502e-01,  2.3600e-01,  6.2734e-02,  4.5556e-01, -3.4958e-01,\n",
       "         5.0657e-01,  5.9292e-02,  3.1880e-01,  5.0372e-02,  4.1883e-02,\n",
       "         5.2443e-01, -3.3194e-01, -2.2018e-01,  4.2729e-01,  1.7477e-01,\n",
       "         6.2380e-01, -2.5859e-02, -6.5565e-01, -3.2560e-01, -5.2927e-01,\n",
       "         1.2883e-01,  2.7590e-01, -3.1361e-01,  1.7080e-01,  3.5777e-01,\n",
       "         3.5979e-01, -1.1718e-01, -9.8629e-02,  4.3394e-01, -2.5169e-01,\n",
       "        -3.0700e-01,  1.3289e-01, -1.9404e-01,  5.1532e-01,  3.4552e-01,\n",
       "         1.2878e-01, -3.0065e-01,  3.7816e-02,  1.7190e-01, -1.9825e-01,\n",
       "         1.1797e+00, -1.8993e-01,  2.7755e-04,  3.4219e-01, -3.5226e-01,\n",
       "        -3.9876e-01, -4.0871e-02,  4.4894e-01, -4.4327e-01, -4.5934e-01,\n",
       "        -1.0254e-01, -7.5459e-01, -3.0153e-01, -4.9936e-02,  2.0407e-01,\n",
       "         4.3949e-01,  1.7297e-01, -8.6860e-02, -4.4700e-01,  6.4088e-02,\n",
       "         3.4653e-01,  2.8575e-01, -1.7064e-01, -1.3702e-01, -2.2776e-01,\n",
       "         5.1265e-01,  1.7876e-01,  1.0231e+00,  1.5751e-01,  4.1487e-02,\n",
       "         3.7005e-01, -7.8745e-01,  3.7644e-02, -4.6069e-01,  3.4793e-01,\n",
       "         5.2389e-01,  7.7282e-02,  1.6763e-01,  2.1061e-01, -6.1286e-02,\n",
       "         2.8609e-01, -1.1961e-02,  2.2970e-01,  5.7258e-02, -3.0108e-02,\n",
       "         2.6470e-02,  4.3411e-01,  4.6380e-02,  1.5811e-01, -4.7164e-02,\n",
       "        -2.4769e-01, -6.1066e-01,  3.6789e-01, -1.5152e-01, -7.1749e-01,\n",
       "         4.9041e-01, -4.9033e-01, -4.1409e-01, -9.0798e-02, -3.3673e-01,\n",
       "         3.8475e-01, -1.0079e+00, -1.2176e-01, -5.3377e-02,  4.3645e-01,\n",
       "        -7.0784e-01, -4.1437e-01,  2.9351e-01, -1.2461e-01,  1.5772e-01,\n",
       "         1.9641e-01,  1.2032e-01, -1.2073e-01,  2.8984e-01, -3.8659e-01,\n",
       "         6.5724e-02,  2.2494e-02,  4.1689e-01, -2.1211e-01, -3.4539e-01,\n",
       "        -3.5772e-01, -2.3839e-01,  1.7092e-01,  2.4235e-01, -1.4027e-01,\n",
       "        -2.1894e-01,  8.4402e-02,  2.0684e-01, -6.8326e-02, -3.7133e-01,\n",
       "        -1.6365e-02, -1.7109e-01, -1.8286e-01,  2.1732e-01,  7.8909e-03,\n",
       "         3.0926e-01, -5.4520e-01,  7.9095e-02,  5.1108e-01,  1.7989e-01,\n",
       "        -3.6406e-01, -4.3173e-02,  5.9772e-01, -3.9696e-01, -3.5357e-01,\n",
       "        -4.8775e-01,  3.5329e-01, -1.9896e-02, -7.8945e-01,  5.7658e-02,\n",
       "         3.8155e-01,  3.9646e-01,  4.4925e-01, -8.8079e-01, -2.3060e-01,\n",
       "         6.0113e-01, -1.3144e-01,  9.2315e-02,  1.5453e-01,  3.3516e-01,\n",
       "        -7.2434e-01,  2.0026e-01,  3.7218e-01, -1.2274e-01,  1.9868e-01,\n",
       "        -7.9941e-01, -5.1266e-02,  1.5352e-01, -2.3456e-01, -1.0968e-01,\n",
       "         2.1385e-01,  4.3861e-01, -1.5794e-02,  2.9095e-01,  8.1493e-01,\n",
       "        -2.8581e-01,  4.0708e-01, -3.8127e-01, -1.3477e-01, -1.7882e-02,\n",
       "        -3.5312e-01, -2.6299e-02,  6.7115e-02,  4.6950e-01,  3.5543e-01,\n",
       "        -6.1383e-02,  1.3043e-02,  5.2435e-01,  5.9840e-01, -2.6635e-01,\n",
       "        -3.7093e-01,  1.5255e-01, -2.3833e-01,  1.4064e-01, -2.7252e-01,\n",
       "        -4.4796e-01, -1.4030e-02, -6.1763e-01, -6.1676e-01,  1.0458e-01,\n",
       "        -3.0993e-01, -4.0825e-01,  3.4125e-01,  9.0173e-03,  7.6978e-01,\n",
       "         1.3293e-01,  1.9577e-01, -1.9099e-02,  8.4232e-01,  1.4135e-02,\n",
       "         7.6768e-01,  4.7727e-02,  4.7458e-02, -1.1742e-01,  2.9822e-01],\n",
       "       dtype=float32),\n",
       " 'stop': False,\n",
       " 'named_entity': None,\n",
       " 'syllables': None,\n",
       " 'phonetic_transcription': None,\n",
       " 'definition': 'scientia\\n\\n\\n ae, \\nf\\n\\nsciens, \\na knowing, knowledge, intelligence, science\\n: nullam rem quae huius viri scientiam fugere possit: nullo\\n                modo poterit oratio mea satis facere vestrae scientiae, i. e. \\nto express as much as you already know\\n: ignoratio futurorum malorum utilior est quam scientia: in\\n                legibus interpretandis: cuius scientiam de omnibus constat\\n            fuisse.‚ÄîOf a particular branch of knowledge, \\nknowledge, skill, expertness, art\\n: ea scientia, quae sit multis profutura: ingenio\\n                scientiƒÅque excellere: vestram scientiam implorarem: scientia atque usus\\n                militum, Cs.: tua scientia\\n            excellens . . . nostra, i. e. \\njurisprudence . . . oratory\\n: Iam efficaci do man≈´s scientiae,\\n                H.: tot artes tantae scientiae, \\nrequiring so great knowledge\\n: physica ipsa et mathematica scientiae sunt eorum,\\n            qui, etc.: nauticarum rerum, Cs.: astrologiae:\\n                dialecticorum: iuris: linguae Gallicae, Cs.: colendorum deorum. ‚Äî\\nTheory\\n: ars, cum eƒÅ non utare, scientiƒÅ tamen\\n                ipsƒÅ teneri potest: te scientiƒÅ augere.',\n",
       " 'stanza_features': 'Case=Nom|Gender=Fem|Number=Sing'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attributes for the token 'scientia'\n",
    "tmp_word = cltk_doc.words[2]\n",
    "tmp_word.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf221a5b",
   "metadata": {},
   "source": [
    "## 3. Definitions\n",
    "\n",
    "Although the `Word` objects have definition attributes, the formatting is a mess (one giant string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1ba03147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition of scientia :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scientia\\n\\n\\n ae, \\nf\\n\\nsciens, \\na knowing, knowledge, intelligence, science\\n: nullam rem quae huius vir ...'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Definition of {tmp_word.string} :\")\n",
    "cltk_doc.words[2].definition[:100] + \" ...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef1c6709",
   "metadata": {},
   "source": [
    "We can use <a html='https://www.latin-is-simple.com/api/'>this site</a> to get a compact definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cf1e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabrica, fabricae f. : (1.) craft, art, craft of metalwork/building, construction/building/making (2.) smith's shop, workshop\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Formats the header of the word\n",
    "def formatHeader(header: str, POS: str) -> str:\n",
    "\n",
    "    # Formatting for verbs\n",
    "    if POS==\"verb\":\n",
    "        principalParts = header.split(\",\")\n",
    "        header = \",\".join(principalParts[:1]+principalParts[2:])\n",
    "        return header\n",
    "\n",
    "    # Formatting for nouns\n",
    "    elif POS==\"noun\":\n",
    "        # decParadigm = header[-1]\n",
    "        # Can use the paradigm to further format the header\n",
    "        # E.g. head = formatNoun(header, decParadigm)\n",
    "        header = re.sub(\"[\\[\\]]\", \"\", header)[:-2]\n",
    "        return header\n",
    "    #elif POS==\"adverb\":\n",
    "    #elif POS==\"adjective\":\n",
    "    #elif POS==\"dempron\"\n",
    "    else:\n",
    "        return header\n",
    "\n",
    "def getDefinition(word: str, POS: str) -> str:\n",
    "    word, POS = word.lower(), POS.lower()\n",
    "\n",
    "    apiURL = \"https://www.latin-is-simple.com/api/vocabulary/search/?query=\"+word+\"&forms_only=true\"\n",
    "    r = requests.get(apiURL)\n",
    "\n",
    "    definition = \"\"\n",
    "\n",
    "    # Only one result for the query\n",
    "    if len(r.json())==1:\n",
    "        entry = r.json()[0]\n",
    "        header = formatHeader(entry['full_name'], entry[\"intern_type\"])\n",
    "        body = entry[\"translations_unstructured\"][\"en\"]\n",
    "        definition = header + \" : \" + body\n",
    "    \n",
    "    # Multiple results (get the first entry that matches POS)\n",
    "    else:\n",
    "        for entry in r.json():\n",
    "            if entry[\"intern_type\"]==POS:\n",
    "                header = formatHeader(entry['full_name'], POS)\n",
    "                body = entry[\"translations_unstructured\"][\"en\"]\n",
    "                definition = header + \" : \" + body\n",
    "                break\n",
    "\n",
    "    return definition \n",
    "\n",
    "# Example\n",
    "print(getDefinition('fabrica', 'noun'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f97855e",
   "metadata": {},
   "source": [
    "### Generate vocabulary aid\n",
    "\n",
    "I frequently generate rudimentary word lists (with declension information) to pre-study vocabulary or study as I read. This idea was inspired to automate creating a latin reader of <a html='https://geoffreysteadman.files.wordpress.com/2019/05/ritchie.may2019.pdf'>this format</a>. \n",
    "It's more useful towards beginners that can have trouble identifying declension forms. The example below makes a vocabulary aid from the Gallic War written by Caesar. More texts are available at the <a html='https://github.com/cltk/lat_text_latin_library'>latin library</a>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "111afdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE BELLO GALLICO : gallia est omnis divisa in partes tres quarum unam incolunt ...\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Corpus/gall1.txt\", \"r\") as f:\n",
    "    x = f.read()\n",
    "\n",
    "# Get the first paragraph \n",
    "l = re.search(r\"\\[ 1 \\] (.*)\", x)\n",
    "x = cleanDoc(drop_latin_punctuation(l[1]), convertLower=True)\n",
    "\n",
    "print(f\"DE BELLO GALLICO : {x[:59]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e08fb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallicWars1 = cltk_nlp.analyze(text=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e26d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omnis not found, POS : determiner\n",
      "divisa not found, POS : adjective\n",
      "tres not found, POS : numeral\n",
      "aliam not found, POS : determiner\n",
      "nostra not found, POS : determiner\n",
      "omnes not found, POS : determiner\n",
      "omnium not found, POS : pronoun\n",
      "quod not found, POS : subordinating_conjunction\n",
      "saepe not found, POS : adverb\n",
      "quoque not found, POS : adverb\n",
      "quod not found, POS : subordinating_conjunction\n",
      "fere not found, POS : adposition\n",
      "belgae not found, POS : adjective\n"
     ]
    }
   ],
   "source": [
    "def generateLex(WordList):\n",
    "    s = set()\n",
    "    for word in WordList:\n",
    "        if not word.stop:\n",
    "            result = getDefinition(word.string, str(word.pos))\n",
    "            # Alert if word wasn't found\n",
    "            if result:\n",
    "                s.add(result)\n",
    "            else:\n",
    "                print(word.string + \" not found, POS : \" + str(word.pos))\n",
    "    return s\n",
    "\n",
    "words = generateLex(gallicWars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0389fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aquitania, Aquitaniae f. : Aquitania, one of the divisions of Gaul/France '\n",
      " '(southwest)',\n",
      " 'Aquitanus/Aquitana/Aquitanum, AO : of Aquitania  (southwest Gaul/France)',\n",
      " 'Belga, Belgae m. : Belgae (pl.)',\n",
      " 'Celtus/Celta/Celtum, AO : Celts',\n",
      " 'Gallia, Galliae f. : Gaul',\n",
      " 'Gallus, Galli m. : Gaul, the Gauls (pl.), cock, rooster',\n",
      " 'Garumna, Garumnae f. : Garonna',\n",
      " 'Helvetia, Helvetiae f. : Switzerland',\n",
      " 'Helvetius, Helvetii m. : Helvetii (pl.), tribe in Central Gaul (Switzerland)',\n",
      " 'Hispania, Hispaniae f. : Hispania, Spain']\n"
     ]
    }
   ],
   "source": [
    "m = sorted(list(words))\n",
    "pprint.pprint(m[:10])\n",
    "with open(\"lexical_list\", \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
