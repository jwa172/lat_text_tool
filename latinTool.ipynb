{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3098a0ac",
   "metadata": {},
   "source": [
    "## Latin pedagogy tool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1aee7",
   "metadata": {},
   "source": [
    "We make use of the CLTK library, a NLP library for classical languages.\n",
    "\n",
    "**Introduction** : https://aclanthology.org/2021.acl-demo.3.pdf\n",
    "\n",
    "**Documentation**\n",
    "* API : https://docs.cltk.org/en/latest/index.html\n",
    "* Demos : https://github.com/cltk/cltk/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0fa6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Architecti est scientia pluribus disciplinis et variis eruditionibus ornata, quae ab ceteris artibus perficiuntur.\n",
    "Opera ea nascitur et fabrica et ratiocinatione.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4b5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100% 112.75 MiB | 1.99 MiB/s \r"
     ]
    }
   ],
   "source": [
    "#corpus = get_corpus_reader(corpus_name='latin_text_perseus', language='latin')\n",
    "from cltk.data.fetch import FetchCorpus\n",
    "corpus_downloader = FetchCorpus(language=\"lat\")\n",
    "corpus_downloader.import_corpus('lat_text_perseus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1239f92",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54675bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.alphabet.lat import drop_latin_punctuation\n",
    "import re\n",
    "\n",
    "def cleanDoc(text, convertLower=False):\n",
    "    # Remove metainfo like [c 1Kb]\n",
    "    cleaned = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    # Remove wide spaces\n",
    "    cleaned = cleaned.replace(\"   \", \" \").replace(\"  \", \" \")\n",
    "    return cleaned.lower() if convertLower else cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c65254f0",
   "metadata": {},
   "source": [
    "## Decliner\n",
    "\n",
    "Declension encodings are described here : https://github.com/cltk/latin_treebank_perseus#readme\n",
    "\n",
    "E.g. --s----n- => singular nominative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a60c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case        Singular    Plural\n",
      "----------  ----------  --------\n",
      "Nominative  le≈ç         le≈çnƒìs\n",
      "Genitive    le≈çnis      le≈çnum\n",
      "Dative      le≈çnƒ´       le≈çnibus\n",
      "Accusative  le≈çnem      le≈çnƒìs\n",
      "Ablative    le≈çne       le≈çnibus\n"
     ]
    }
   ],
   "source": [
    "from cltk.morphology.lat import CollatinusDecliner\n",
    "from collections import OrderedDict\n",
    "from tabulate import tabulate\n",
    "\n",
    "words = ['leo', 'via']\n",
    "def declensions(rootWords: list)-> dict:\n",
    "    dec, decliner = {}, CollatinusDecliner()\n",
    "    for word in rootWords:\n",
    "        # Expect root words only\n",
    "        try: dec[word] = decliner.decline(word)\n",
    "        except Exception: print('Not a root word')\n",
    "    return dec\n",
    "\n",
    "# Usage example : declension table (only nouns for now)\n",
    "def printDecTable(lemma, POS):\n",
    "\n",
    "    rows = []\n",
    "    cases = {'n':'Nominative',\n",
    "             'g':'Genitive',\n",
    "             'd':'Dative',\n",
    "             'a':'Accusative',\n",
    "             'b':'Ablative'}\n",
    "\n",
    "    d = OrderedDict({c: {} for c in cases.keys()})\n",
    "    if POS==\"noun\":\n",
    "        declens = CollatinusDecliner().decline(lemma)\n",
    "        for dec, code in declens:\n",
    "            number, case = code[2], code[7]\n",
    "            if case in d: d[case][number] = macronizer(dec).lower()\n",
    "        \n",
    "        for key, val in d.items():\n",
    "            row =[cases[key]]+list(val.values())\n",
    "            rows.append(row)\n",
    "            \n",
    "    print(tabulate(rows, headers=['Case', 'Singular', 'Plural']))\n",
    "\n",
    "decs = declensions(words)\n",
    "printDecTable(\"leo\", \"noun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3790c",
   "metadata": {},
   "source": [
    "## Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce17659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example : ['filias', 'pueri', 'cecini', 'variis'] -> ['filia', 'puer', 'cano', 'varius1']\n"
     ]
    }
   ],
   "source": [
    "from cltk.lemmatize.lat import LatinBackoffLemmatizer\n",
    "\n",
    "# Returns tuples of (original, root)\n",
    "# Requires lower-case, non-macron inputs\n",
    "def lemmatize(tokens: list)-> list:\n",
    "    lemmatizer = LatinBackoffLemmatizer()\n",
    "    tokens = lemmatizer.lemmatize(tokens)\n",
    "    return [root for _, root in tokens]\n",
    "\n",
    "tokens = [\"filias\", \"pueri\", \"cecini\", \"variis\"]\n",
    "print(f\"Example : {tokens} -> {lemmatize(tokens)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ed74c",
   "metadata": {},
   "source": [
    "## Macronizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da228339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architectƒ´ est scientiƒÅ pl≈´ribus disciplƒ´nƒ´s et variƒ´s ƒìrudƒ´ti≈çnibus ≈çrnƒÅta , quae ab cƒìterƒ´s artibus perficiuntur . opera ea nƒÅscitur et fabricƒÅ et rati≈çcinƒÅti≈çne .\n"
     ]
    }
   ],
   "source": [
    "from cltk.prosody.lat.macronizer import Macronizer\n",
    "\n",
    "# NOTE: subpar accuracy for the macronizer \n",
    "def macronizer(text: str) -> str:\n",
    "    macronizer = Macronizer(\"tag_tnt\")\n",
    "    text = macronizer.macronize_text(text)\n",
    "    return text\n",
    "\n",
    "tƒìxt = macronizer(text)\n",
    "print(tƒìxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a21599",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41995ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.sentence.lat import LatinPunktSentenceTokenizer\n",
    "from cltk.alphabet.text_normalization import remove_non_latin\n",
    "from cltk.tokenizers.lat.lat import LatinWordTokenizer\n",
    "\n",
    "# Sentence tokenizer\n",
    "def sentTokenize(doc: str, punct=True) -> list:\n",
    "    sent_tokenize = LatinPunktSentenceTokenizer()\n",
    "    sentences = sent_tokenize.tokenize(doc)\n",
    "    return [remove_non_latin(s).lower() for s in sentences] if punct else sentences\n",
    "\n",
    "# Word tokenizer\n",
    "def word_Tokenizer(sent: str) -> list:\n",
    "    word_tokenize = LatinWordTokenizer()\n",
    "    tokens = word_tokenize.tokenize(sent)\n",
    "    return tokens\n",
    "\n",
    "sentences = sentTokenize(text)\n",
    "tokens = word_Tokenizer(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc6a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.6'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "# NLP pipeline\n",
    "from cltk import NLP\n",
    "cltk_nlp = NLP(language=\"lat\")\n",
    "\n",
    "text = drop_latin_punctuation(cleanDoc(text, convertLower=True))\n",
    "cltk_doc = cltk_nlp.analyze(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0ef9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architectus, architecti m. : architect, master-builder, inventor, designer, maker, author, deviser\n",
      "scientia, scientiae f. : knowledge\n",
      "plus, pluris M : more, several. many\n",
      "disciplina, disciplinae f. : teaching, instruction, education, training, discipline, method, science, study\n",
      "varius/varia/varium, AO : different, various, diverse, changing, colored, party colored, variegated\n",
      "eruditio, eruditionis f. : instruction/teaching/education, learning/erudition, taught knowledge, culture\n",
      "orno, ornare A, ornavi, ornatum : adorn, decorate\n",
      "ceterus/cetera/ceterum, AO : remaining, rest\n",
      "ars, artis f. : art, skill\n",
      "perficio, perficere M, perfeci, perfectum : complete, finish, execute, bring about, accomplish, do thoroughly\n",
      "opus, operis n. : work, achievement, oeuvre\n",
      "nascor, nasci C, natus sum (Dep.) : (1.) be born (2.) spring forth, arise\n",
      "\n",
      "ratiocinatio, ratiocinationis f. : reasoning, esp. a form of argument, syllogism\n"
     ]
    }
   ],
   "source": [
    "# Word attributes\n",
    "# word.lemma\n",
    "# word.gender (for nouns)\n",
    "# word.pos (part of speech nouns etc)\n",
    "# word.string\n",
    "# word.features\n",
    "# word.xpos (treebank POS tag)\n",
    "# word.upos (universal POS tag)\n",
    "#   For verbs : Aspect, case, degree, gender\n",
    "#   For nouns : case, degree, gender, number\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf221a5b",
   "metadata": {},
   "source": [
    "## Dictionary 1\n",
    "\n",
    "Use the following API to get a succinct definition: https://www.latin-is-simple.com/api/\n",
    "\n",
    "\"intern_type\" can has the following values:\n",
    "- \"dempron\" for demonstrative pronouns\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0cf1e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabrico, fabricare A, fabricavi, fabricatum : build/construct/fashion/forge/shape, train, get ready (meal), invent/devise\n",
      "fabrica, fabricae f. : (1.) craft, art, craft of metalwork/building, construction/building/making (2.) smith's shop, workshop\n",
      "architectus, architecti m. : architect, master-builder, inventor, designer, maker, author, deviser\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Formats the header of the word\n",
    "def formatHeader(header: str, POS: str) -> str:\n",
    "\n",
    "    # Formatting for verbs\n",
    "    if POS==\"verb\":\n",
    "        principalParts = header.split(\",\")\n",
    "        header = \",\".join(principalParts[:1]+principalParts[2:])\n",
    "        return header\n",
    "\n",
    "    # Formatting for nouns\n",
    "    elif POS==\"noun\":\n",
    "        # decParadigm = header[-1]\n",
    "        # Can use the paradigm to further format the header\n",
    "        # E.g. head = formatNoun(header, decParadigm)\n",
    "        header = re.sub(\"[\\[\\]]\", \"\", header)[:-2]\n",
    "        return header\n",
    "    #elif POS==\"adverb\":\n",
    "    #elif POS==\"adjective\":\n",
    "    #elif POS==\"dempron\"\n",
    "    else:\n",
    "        return header\n",
    "\n",
    "def getDefinition(word: str, POS: str) -> str:\n",
    "    word, POS = word.lower(), POS.lower()\n",
    "\n",
    "    apiURL = \"https://www.latin-is-simple.com/api/vocabulary/search/?query=\"+word+\"&forms_only=true\"\n",
    "    r = requests.get(apiURL)\n",
    "\n",
    "    definition = \"\"\n",
    "\n",
    "    # Only one result\n",
    "    if len(r.json())==1:\n",
    "        entry = r.json()[0]\n",
    "        header = formatHeader(entry['full_name'], entry[\"intern_type\"])\n",
    "        body = entry[\"translations_unstructured\"][\"en\"]\n",
    "        definition = header + \" : \" + body\n",
    "    \n",
    "    # Multiple results (get the first entry that matches POS)\n",
    "    else:\n",
    "        for entry in r.json():\n",
    "            if entry[\"intern_type\"]==POS:\n",
    "                header = formatHeader(entry['full_name'], POS)\n",
    "                body = entry[\"translations_unstructured\"][\"en\"]\n",
    "                definition = header + \" : \" + body\n",
    "                break\n",
    "\n",
    "    return definition \n",
    "\n",
    "# Example\n",
    "print(getDefinition('fabrica', 'noun'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f97855e",
   "metadata": {},
   "source": [
    "## Use case - generate lexical list\n",
    "\n",
    "Gallic wars of Caesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "111afdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Corpus/gall1.txt\", \"r\") as f:\n",
    "    x = f.read()\n",
    "\n",
    "# Get the first paragraph \n",
    "l = re.search(r\"\\[ 1 \\] (.*)\", x)\n",
    "x = cleanDoc(drop_latin_punctuation(l[1]), convertLower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e08fb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallicWars1 = cltk_nlp.analyze(text=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4e26d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLex(WordList):\n",
    "    s = set()\n",
    "    for word in WordList:\n",
    "        if not word.stop:\n",
    "            result = getDefinition(word.string, str(word.pos))\n",
    "            # Need to alert if word wasn't found\n",
    "            if result:\n",
    "                s.add(result)\n",
    "            else:\n",
    "                print(word.string + \" not found, POS : \" + str(word.pos))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a2a20cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omnis not found\n",
      "divisa not found\n",
      "tres not found\n",
      "aliam not found\n",
      "nostra not found\n",
      "omnes not found\n",
      "omnium not found\n",
      "quod not found\n",
      "saepe not found\n",
      "quoque not found\n",
      "quod not found\n",
      "fere not found\n",
      "belgae not found\n"
     ]
    }
   ],
   "source": [
    "words = generateLex(gallicWars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0389fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sorted(list(words))\n",
    "with open(\"lexical_list\", \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
