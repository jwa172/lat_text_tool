{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3098a0ac",
   "metadata": {},
   "source": [
    "## Latin pedagogy tool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1aee7",
   "metadata": {},
   "source": [
    "We make use of the CLTK library, a NLP library for classical languages.\n",
    "\n",
    "**Introduction** : https://aclanthology.org/2021.acl-demo.3.pdf\n",
    "\n",
    "**Documentation**\n",
    "* API : https://docs.cltk.org/en/latest/index.html\n",
    "* Demos : https://github.com/cltk/cltk/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fa6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Architecti est scientia pluribus disciplinis et variis eruditionibus ornata, quae ab ceteris artibus perficiuntur.\n",
    "Opera ea nascitur et fabrica et ratiocinatione.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4b5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100% 112.75 MiB | 1.99 MiB/s \r"
     ]
    }
   ],
   "source": [
    "#corpus = get_corpus_reader(corpus_name='latin_text_perseus', language='latin')\n",
    "from cltk.data.fetch import FetchCorpus\n",
    "corpus_downloader = FetchCorpus(language=\"lat\")\n",
    "corpus_downloader.import_corpus('lat_text_perseus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1239f92",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54675bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# For imported text\n",
    "# Remove metainfo like [c 1Kb]\n",
    "def cleanDoc(text, convertLower=False):\n",
    "    cleaned = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    cleaned = cleaned.replace(\"   \", \" \").replace(\"  \", \" \")\n",
    "    return cleaned.lower() if convertLower else cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65254f0",
   "metadata": {},
   "source": [
    "## Decliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73a60c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a root word\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'via': [('via', '--s----n-'),\n",
       "  ('via', '--s----v-'),\n",
       "  ('viam', '--s----a-'),\n",
       "  ('viae', '--s----g-'),\n",
       "  ('viae', '--s----d-'),\n",
       "  ('via', '--s----b-'),\n",
       "  ('viae', '--p----n-'),\n",
       "  ('viae', '--p----v-'),\n",
       "  ('vias', '--p----a-'),\n",
       "  ('viarum', '--p----g-'),\n",
       "  ('viis', '--p----d-'),\n",
       "  ('viis', '--p----b-')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cltk.morphology.lat import CollatinusDecliner\n",
    "\n",
    "words = ['leonis', 'via']#['via', 'arbor', 'leo']\n",
    "def declensions(rootWords: list)-> dict:\n",
    "    dec, decliner = {}, CollatinusDecliner()\n",
    "    for word in rootWords:\n",
    "        # Expect root words only\n",
    "        try: dec[word] = decliner.decline(word)\n",
    "        except Exception: print('Not a root word')\n",
    "    return dec\n",
    "\n",
    "# Only for noun for now\n",
    "#def printDecTable()\n",
    "decs = declensions(words)\n",
    "decs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3790c",
   "metadata": {},
   "source": [
    "## Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ce17659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filia', 'puer', 'cano']\n"
     ]
    }
   ],
   "source": [
    "from cltk.lemmatize.lat import LatinBackoffLemmatizer\n",
    "\n",
    "# Returns tuples of (declined, root)\n",
    "# Requires lower-case, non-macron inputs\n",
    "def lemmatize(tokens: list)-> list:\n",
    "    lemmatizer = LatinBackoffLemmatizer()\n",
    "    tokens = lemmatizer.lemmatize(tokens)\n",
    "    return [root for _, root in tokens]\n",
    "\n",
    "tokens = [\"filias\", \"pueri\", \"cano\"]\n",
    "\n",
    "lem = lemmatize(tokens)\n",
    "print(lem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ed74c",
   "metadata": {},
   "source": [
    "## Macronizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da228339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solƒìs occƒ´dere et redƒ´re possunt\n"
     ]
    }
   ],
   "source": [
    "from cltk.prosody.lat.macronizer import Macronizer\n",
    "\n",
    "# NOTE: subpar accuracy for the macronizer \n",
    "def macronizer(text: str) -> str:\n",
    "    macronizer = Macronizer(\"tag_tnt\")\n",
    "    text = macronizer.macronize_text(\"Soles occidere et redire possunt\")\n",
    "    return text\n",
    "\n",
    "tƒìxt = macronizer(text)\n",
    "print(tƒìxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a21599",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41995ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['architecti',\n",
       " 'est',\n",
       " 'scientia',\n",
       " 'pluribus',\n",
       " 'disciplinis',\n",
       " 'et',\n",
       " 'variis',\n",
       " 'eruditionibus',\n",
       " 'ornata',\n",
       " 'quae',\n",
       " 'ab',\n",
       " 'ceteris',\n",
       " 'artibus',\n",
       " 'perficiuntur']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cltk.sentence.lat import LatinPunktSentenceTokenizer\n",
    "from cltk.alphabet.text_normalization import remove_non_latin\n",
    "from cltk.tokenizers.lat.lat import LatinWordTokenizer\n",
    "\n",
    "# Sentence tokenizer\n",
    "def sentTokenize(doc: str, punct=True) -> list:\n",
    "    sent_tokenize = LatinPunktSentenceTokenizer()\n",
    "    sentences = sent_tokenize.tokenize(doc)\n",
    "    return [remove_non_latin(s).lower() for s in sentences] if punct else sentences\n",
    "\n",
    "# Word tokenizer\n",
    "def word_Tokenizer(sent: str) -> list:\n",
    "    word_tokenize = LatinWordTokenizer()\n",
    "    tokens = word_tokenize.tokenize(sent)\n",
    "    return tokens\n",
    "\n",
    "sentences = sentTokenize(text)\n",
    "tokens = word_Tokenizer(sentences[0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2e7595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['architectus',\n",
       " 'sum',\n",
       " 'scientia',\n",
       " 'multus',\n",
       " 'disciplina',\n",
       " 'et',\n",
       " 'varius1',\n",
       " 'eruditio',\n",
       " 'orno',\n",
       " 'qui',\n",
       " 'ab',\n",
       " 'ceterus',\n",
       " 'ars',\n",
       " 'perficio']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_words=lemmatize(tokens)\n",
    "root_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.6'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "# NLP pipeline - not working of now\n",
    "#from cltk import NLP\n",
    "#cltk_nlp = NLP(language=\"lat\")\n",
    "# TROUBLE LINE cltk_doc = cltk_nlp.analyze(text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
